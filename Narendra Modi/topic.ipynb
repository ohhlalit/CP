{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all necesary libraries\n",
    "import pandas as pd\n",
    "import nltk \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from gensim.models import Word2Vec\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cleaned data for vectorization \n",
    "df_data = pd.read_csv(\"C:/Users/abcd/Downloads/FINAL_PM_Modi_Speech_Cleaned_string.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Date</th>\n",
       "      <th>Speech</th>\n",
       "      <th>Title</th>\n",
       "      <th>Cleaned_Speech</th>\n",
       "      <th>Cleaned_Speech_string</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NMS1</td>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>Governor of Andhra Pradesh, Shri E. S. L. Nara...</td>\n",
       "      <td>PM's Address at the Inauguration of the 104th ...</td>\n",
       "      <td>['governor andhra pradesh shri e l narasimhan ...</td>\n",
       "      <td>governor andhra pradesh shri e l narasimhan ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NMS2</td>\n",
       "      <td>2017-01-09</td>\n",
       "      <td>Chief Minister of Gujarat Shri Vijay Rupani ji...</td>\n",
       "      <td>Text of PM's address at the Inauguration of No...</td>\n",
       "      <td>['chief minister gujarat shri vijay rupani ji ...</td>\n",
       "      <td>chief minister gujarat shri vijay rupani ji co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NMS3</td>\n",
       "      <td>2017-01-09</td>\n",
       "      <td>I  am delighted to be here at Gift City to ina...</td>\n",
       "      <td>Text of PM’s address on the occasion of Inaugu...</td>\n",
       "      <td>['delighted gift city inaugurate india first i...</td>\n",
       "      <td>delighted gift city inaugurate india first int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NMS4</td>\n",
       "      <td>2017-02-01</td>\n",
       "      <td>I congratulate the Finance Minister Arun Jaitl...</td>\n",
       "      <td>English rendering of the Prime Minister’s Stat...</td>\n",
       "      <td>['congratulate finance minister arun jaitley j...</td>\n",
       "      <td>congratulate finance minister arun jaitley jee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NMS5</td>\n",
       "      <td>2017-02-05</td>\n",
       "      <td>Sri Pejavar Math’s most respected Sri Vishwesh...</td>\n",
       "      <td>English rendering of the text of PM’s address ...</td>\n",
       "      <td>['sri pejavar math respected sri vishwesh tirt...</td>\n",
       "      <td>sri pejavar math respected sri vishwesh tirth ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1177</th>\n",
       "      <td>NMS1178</td>\n",
       "      <td>2023-04-09</td>\n",
       "      <td>My colleagues in the Union Cabinet Shri Bhupen...</td>\n",
       "      <td>English rendering of PM’s address at the inaug...</td>\n",
       "      <td>['colleague union cabinet shri bhupender yadav...</td>\n",
       "      <td>colleague union cabinet shri bhupender yadav j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1178</th>\n",
       "      <td>NMS1179</td>\n",
       "      <td>2023-04-12</td>\n",
       "      <td>Namaskar! \\n\\nThe campaign to provide governme...</td>\n",
       "      <td>English rendering of PM’s address at training ...</td>\n",
       "      <td>['namaskar', 'campaign provide government job ...</td>\n",
       "      <td>namaskar campaign provide government job youth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1179</th>\n",
       "      <td>NMS1180</td>\n",
       "      <td>2023-04-12</td>\n",
       "      <td>Namaskar, Governor of Rajasthan Shri Kalraj Mi...</td>\n",
       "      <td>English rendering of PM’s address during flagg...</td>\n",
       "      <td>['namaskar governor rajasthan shri kalraj mish...</td>\n",
       "      <td>namaskar governor rajasthan shri kalraj mishra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1180</th>\n",
       "      <td>NMS1181</td>\n",
       "      <td>2023-04-14</td>\n",
       "      <td>Governor of Assam Shri Gulab Chand Kataria ji,...</td>\n",
       "      <td>English rendering of PM’s address at inaugurat...</td>\n",
       "      <td>['governor assam shri gulab chand kataria ji c...</td>\n",
       "      <td>governor assam shri gulab chand kataria ji chi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1181</th>\n",
       "      <td>NMS1182</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>President of the World Bank, Her Excellency, t...</td>\n",
       "      <td>Text of Prime Minister’s video message at the ...</td>\n",
       "      <td>['president world bank excellency minister ene...</td>\n",
       "      <td>president world bank excellency minister energ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1182 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index        Date                                             Speech   \n",
       "0        NMS1  2017-01-03  Governor of Andhra Pradesh, Shri E. S. L. Nara...  \\\n",
       "1        NMS2  2017-01-09  Chief Minister of Gujarat Shri Vijay Rupani ji...   \n",
       "2        NMS3  2017-01-09  I  am delighted to be here at Gift City to ina...   \n",
       "3        NMS4  2017-02-01  I congratulate the Finance Minister Arun Jaitl...   \n",
       "4        NMS5  2017-02-05  Sri Pejavar Math’s most respected Sri Vishwesh...   \n",
       "...       ...         ...                                                ...   \n",
       "1177  NMS1178  2023-04-09  My colleagues in the Union Cabinet Shri Bhupen...   \n",
       "1178  NMS1179  2023-04-12  Namaskar! \\n\\nThe campaign to provide governme...   \n",
       "1179  NMS1180  2023-04-12  Namaskar, Governor of Rajasthan Shri Kalraj Mi...   \n",
       "1180  NMS1181  2023-04-14  Governor of Assam Shri Gulab Chand Kataria ji,...   \n",
       "1181  NMS1182  2023-04-15  President of the World Bank, Her Excellency, t...   \n",
       "\n",
       "                                                  Title   \n",
       "0     PM's Address at the Inauguration of the 104th ...  \\\n",
       "1     Text of PM's address at the Inauguration of No...   \n",
       "2     Text of PM’s address on the occasion of Inaugu...   \n",
       "3     English rendering of the Prime Minister’s Stat...   \n",
       "4     English rendering of the text of PM’s address ...   \n",
       "...                                                 ...   \n",
       "1177  English rendering of PM’s address at the inaug...   \n",
       "1178  English rendering of PM’s address at training ...   \n",
       "1179  English rendering of PM’s address during flagg...   \n",
       "1180  English rendering of PM’s address at inaugurat...   \n",
       "1181  Text of Prime Minister’s video message at the ...   \n",
       "\n",
       "                                         Cleaned_Speech   \n",
       "0     ['governor andhra pradesh shri e l narasimhan ...  \\\n",
       "1     ['chief minister gujarat shri vijay rupani ji ...   \n",
       "2     ['delighted gift city inaugurate india first i...   \n",
       "3     ['congratulate finance minister arun jaitley j...   \n",
       "4     ['sri pejavar math respected sri vishwesh tirt...   \n",
       "...                                                 ...   \n",
       "1177  ['colleague union cabinet shri bhupender yadav...   \n",
       "1178  ['namaskar', 'campaign provide government job ...   \n",
       "1179  ['namaskar governor rajasthan shri kalraj mish...   \n",
       "1180  ['governor assam shri gulab chand kataria ji c...   \n",
       "1181  ['president world bank excellency minister ene...   \n",
       "\n",
       "                                  Cleaned_Speech_string  \n",
       "0     governor andhra pradesh shri e l narasimhan ch...  \n",
       "1     chief minister gujarat shri vijay rupani ji co...  \n",
       "2     delighted gift city inaugurate india first int...  \n",
       "3     congratulate finance minister arun jaitley jee...  \n",
       "4     sri pejavar math respected sri vishwesh tirth ...  \n",
       "...                                                 ...  \n",
       "1177  colleague union cabinet shri bhupender yadav j...  \n",
       "1178  namaskar campaign provide government job youth...  \n",
       "1179  namaskar governor rajasthan shri kalraj mishra...  \n",
       "1180  governor assam shri gulab chand kataria ji chi...  \n",
       "1181  president world bank excellency minister energ...  \n",
       "\n",
       "[1182 rows x 6 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apiTokenController(text):\n",
    "    if isinstance(text, str):\n",
    "        tokens = text.split()\n",
    "        merged_text = ' '.join(tokens[:2500])\n",
    "        return merged_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data[\"prompt\"] = df_data['Speech'].apply(apiTokenController)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "# Set up OpenAI API credentials\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "# Define a function to perform topic modeling using GPT-3\n",
    "def topic_modeling(text):\n",
    "    \n",
    "    # Use GPT-3 to generate the top topics and their corresponding words\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"text-davinci-002\",\n",
    "        prompt=f\"Based on the text provided ({text}), what are the central themes or subjects that the author is exploring?\",\n",
    "        max_tokens= 100,\n",
    "        n=1,\n",
    "        stop=None,\n",
    "        temperature=0.5\n",
    "    )\n",
    "    topic = response.choices[0].text.split(\"\\n\")\n",
    "    # Return the top topics\n",
    "    return topic\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=df_data['prompt'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "You exceeded your current quota, please check your plan and billing details.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[130], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m h \u001b[39m=\u001b[39m topic_modeling(t)\n",
      "Cell \u001b[1;32mIn[126], line 10\u001b[0m, in \u001b[0;36mtopic_modeling\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtopic_modeling\u001b[39m(text):\n\u001b[0;32m      8\u001b[0m     \n\u001b[0;32m      9\u001b[0m     \u001b[39m# Use GPT-3 to generate the top topics and their corresponding words\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m     response \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mCompletion\u001b[39m.\u001b[39;49mcreate(\n\u001b[0;32m     11\u001b[0m         engine\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtext-davinci-002\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     12\u001b[0m         prompt\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mBased on the text provided (\u001b[39;49m\u001b[39m{\u001b[39;49;00mtext\u001b[39m}\u001b[39;49;00m\u001b[39m), what are the central themes or subjects that the author is exploring?\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     13\u001b[0m         max_tokens\u001b[39m=\u001b[39;49m \u001b[39m100\u001b[39;49m,\n\u001b[0;32m     14\u001b[0m         n\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[0;32m     15\u001b[0m         stop\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m     16\u001b[0m         temperature\u001b[39m=\u001b[39;49m\u001b[39m0.5\u001b[39;49m\n\u001b[0;32m     17\u001b[0m     )\n\u001b[0;32m     18\u001b[0m     topic \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mchoices[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mtext\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     19\u001b[0m     \u001b[39m# Return the top topics\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\abcd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\api_resources\\completion.py:25\u001b[0m, in \u001b[0;36mCompletion.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[1;32mc:\\Users\\abcd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[0;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[0;32m    137\u001b[0m ):\n\u001b[0;32m    138\u001b[0m     (\n\u001b[0;32m    139\u001b[0m         deployment_id,\n\u001b[0;32m    140\u001b[0m         engine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[0;32m    151\u001b[0m     )\n\u001b[1;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[0;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    155\u001b[0m         url,\n\u001b[0;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[0;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[0;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[0;32m    161\u001b[0m     )\n\u001b[0;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[0;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[0;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[1;32mc:\\Users\\abcd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\api_requestor.py:226\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[0;32m    206\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    207\u001b[0m     method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    214\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    215\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[0;32m    216\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[0;32m    217\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[0;32m    218\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    224\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[0;32m    225\u001b[0m     )\n\u001b[1;32m--> 226\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[0;32m    227\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[1;32mc:\\Users\\abcd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\api_requestor.py:620\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[1;34m(self, result, stream)\u001b[0m\n\u001b[0;32m    612\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    613\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[0;32m    614\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    615\u001b[0m         )\n\u001b[0;32m    616\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[0;32m    617\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    618\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    619\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m--> 620\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[0;32m    621\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m    622\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[0;32m    623\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    624\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    625\u001b[0m         ),\n\u001b[0;32m    626\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    627\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\abcd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\api_requestor.py:683\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    681\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[0;32m    682\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[1;32m--> 683\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[0;32m    684\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[0;32m    685\u001b[0m     )\n\u001b[0;32m    686\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[1;31mRateLimitError\u001b[0m: You exceeded your current quota, please check your plan and billing details."
     ]
    }
   ],
   "source": [
    "h = topic_modeling(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1182/1182 [23:21<00:00,  1.19s/it] \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def process_data(df_data):\n",
    "    error_column = []\n",
    "\n",
    "    for i in tqdm(range(len(df_data))):\n",
    "        if df_data['topic'][i] == ' ':\n",
    "            try:\n",
    "                topic = topic_modeling(df_data['prompt'][i])\n",
    "                df_data['topic'][i] = topic\n",
    "                error_column.append(None)\n",
    "            except Exception as e:\n",
    "                error_column.append(str(e))\n",
    "        else:\n",
    "            error_column.append(None)\n",
    "\n",
    "    df_data['error'] = error_column\n",
    "    return df_data\n",
    "\n",
    "df_data = process_data(df_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data['topic'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'return' outside function (559438029.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[159], line 3\u001b[1;36m\u001b[0m\n\u001b[1;33m    return i\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m 'return' outside function\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1000,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = df_data['error'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "error\n",
       "Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))                                                            1\n",
       "This model's maximum context length is 4097 tokens, however you requested 4244 tokens (4144 in your prompt; 100 for the completion). Please reduce your prompt; or completion length.    1\n",
       "This model's maximum context length is 4097 tokens, however you requested 4402 tokens (4302 in your prompt; 100 for the completion). Please reduce your prompt; or completion length.    1\n",
       "This model's maximum context length is 4097 tokens, however you requested 4744 tokens (4644 in your prompt; 100 for the completion). Please reduce your prompt; or completion length.    1\n",
       "This model's maximum context length is 4097 tokens, however you requested 4239 tokens (4139 in your prompt; 100 for the completion). Please reduce your prompt; or completion length.    1\n",
       "This model's maximum context length is 4097 tokens, however you requested 4486 tokens (4386 in your prompt; 100 for the completion). Please reduce your prompt; or completion length.    1\n",
       "This model's maximum context length is 4097 tokens, however you requested 4260 tokens (4160 in your prompt; 100 for the completion). Please reduce your prompt; or completion length.    1\n",
       "This model's maximum context length is 4097 tokens, however you requested 6062 tokens (5962 in your prompt; 100 for the completion). Please reduce your prompt; or completion length.    1\n",
       "This model's maximum context length is 4097 tokens, however you requested 4141 tokens (4041 in your prompt; 100 for the completion). Please reduce your prompt; or completion length.    1\n",
       "This model's maximum context length is 4097 tokens, however you requested 5091 tokens (4991 in your prompt; 100 for the completion). Please reduce your prompt; or completion length.    1\n",
       "This model's maximum context length is 4097 tokens, however you requested 4140 tokens (4040 in your prompt; 100 for the completion). Please reduce your prompt; or completion length.    1\n",
       "This model's maximum context length is 4097 tokens, however you requested 4364 tokens (4264 in your prompt; 100 for the completion). Please reduce your prompt; or completion length.    1\n",
       "This model's maximum context length is 4097 tokens, however you requested 4195 tokens (4095 in your prompt; 100 for the completion). Please reduce your prompt; or completion length.    1\n",
       "This model's maximum context length is 4097 tokens, however you requested 4728 tokens (4628 in your prompt; 100 for the completion). Please reduce your prompt; or completion length.    1\n",
       "This model's maximum context length is 4097 tokens, however you requested 4673 tokens (4573 in your prompt; 100 for the completion). Please reduce your prompt; or completion length.    1\n",
       "This model's maximum context length is 4097 tokens, however you requested 4145 tokens (4045 in your prompt; 100 for the completion). Please reduce your prompt; or completion length.    1\n",
       "This model's maximum context length is 4097 tokens, however you requested 4300 tokens (4200 in your prompt; 100 for the completion). Please reduce your prompt; or completion length.    1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '',\n",
       " 'A. The central themes of the text are science and technology, and their role in national development.',\n",
       " '',\n",
       " 'B. The text discusses the challenges and opportunities that science and technology present to the nation.',\n",
       " '',\n",
       " 'C. The text discusses the need for scientific research and development in order to meet the needs of the nation.',\n",
       " '',\n",
       " 'D. The text discusses the importance of science and technology in meeting the societal needs of the nation.']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data['topic'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '', 'The central themes that the author is exploring are the importance of solar energy, the need for innovation in solar technology, the need for international cooperation to promote solar energy, and the potential benefits of solar energy for developing countries.']\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
