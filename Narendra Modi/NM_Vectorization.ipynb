{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cleaned data for vectorization \n",
    "df_data = pd.read_csv(\"E:\\Tarang\\Ashoka\\Python\\PYTHON PROJECT\\FINAL_PM_Modi_Speech_Cleaned_string.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Date</th>\n",
       "      <th>Speech</th>\n",
       "      <th>Title</th>\n",
       "      <th>Cleaned_Speech</th>\n",
       "      <th>Cleaned_Speech_string</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NMS1</td>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>Governor of Andhra Pradesh, Shri E. S. L. Nara...</td>\n",
       "      <td>PM's Address at the Inauguration of the 104th ...</td>\n",
       "      <td>['governor andhra pradesh shri e l narasimhan ...</td>\n",
       "      <td>governor andhra pradesh shri e l narasimhan ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NMS2</td>\n",
       "      <td>2017-01-09</td>\n",
       "      <td>Chief Minister of Gujarat Shri Vijay Rupani ji...</td>\n",
       "      <td>Text of PM's address at the Inauguration of No...</td>\n",
       "      <td>['chief minister gujarat shri vijay rupani ji ...</td>\n",
       "      <td>chief minister gujarat shri vijay rupani ji co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NMS3</td>\n",
       "      <td>2017-01-09</td>\n",
       "      <td>I  am delighted to be here at Gift City to ina...</td>\n",
       "      <td>Text of PM’s address on the occasion of Inaugu...</td>\n",
       "      <td>['delighted gift city inaugurate india first i...</td>\n",
       "      <td>delighted gift city inaugurate india first int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NMS4</td>\n",
       "      <td>2017-02-01</td>\n",
       "      <td>I congratulate the Finance Minister Arun Jaitl...</td>\n",
       "      <td>English rendering of the Prime Minister’s Stat...</td>\n",
       "      <td>['congratulate finance minister arun jaitley j...</td>\n",
       "      <td>congratulate finance minister arun jaitley jee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NMS5</td>\n",
       "      <td>2017-02-05</td>\n",
       "      <td>Sri Pejavar Math’s most respected Sri Vishwesh...</td>\n",
       "      <td>English rendering of the text of PM’s address ...</td>\n",
       "      <td>['sri pejavar math respected sri vishwesh tirt...</td>\n",
       "      <td>sri pejavar math respected sri vishwesh tirth ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1177</th>\n",
       "      <td>NMS1178</td>\n",
       "      <td>2023-04-09</td>\n",
       "      <td>My colleagues in the Union Cabinet Shri Bhupen...</td>\n",
       "      <td>English rendering of PM’s address at the inaug...</td>\n",
       "      <td>['colleague union cabinet shri bhupender yadav...</td>\n",
       "      <td>colleague union cabinet shri bhupender yadav j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1178</th>\n",
       "      <td>NMS1179</td>\n",
       "      <td>2023-04-12</td>\n",
       "      <td>Namaskar! \\n\\nThe campaign to provide governme...</td>\n",
       "      <td>English rendering of PM’s address at training ...</td>\n",
       "      <td>['namaskar', 'campaign provide government job ...</td>\n",
       "      <td>namaskar campaign provide government job youth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1179</th>\n",
       "      <td>NMS1180</td>\n",
       "      <td>2023-04-12</td>\n",
       "      <td>Namaskar, Governor of Rajasthan Shri Kalraj Mi...</td>\n",
       "      <td>English rendering of PM’s address during flagg...</td>\n",
       "      <td>['namaskar governor rajasthan shri kalraj mish...</td>\n",
       "      <td>namaskar governor rajasthan shri kalraj mishra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1180</th>\n",
       "      <td>NMS1181</td>\n",
       "      <td>2023-04-14</td>\n",
       "      <td>Governor of Assam Shri Gulab Chand Kataria ji,...</td>\n",
       "      <td>English rendering of PM’s address at inaugurat...</td>\n",
       "      <td>['governor assam shri gulab chand kataria ji c...</td>\n",
       "      <td>governor assam shri gulab chand kataria ji chi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1181</th>\n",
       "      <td>NMS1182</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>President of the World Bank, Her Excellency, t...</td>\n",
       "      <td>Text of Prime Minister’s video message at the ...</td>\n",
       "      <td>['president world bank excellency minister ene...</td>\n",
       "      <td>president world bank excellency minister energ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1182 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index        Date                                             Speech  \\\n",
       "0        NMS1  2017-01-03  Governor of Andhra Pradesh, Shri E. S. L. Nara...   \n",
       "1        NMS2  2017-01-09  Chief Minister of Gujarat Shri Vijay Rupani ji...   \n",
       "2        NMS3  2017-01-09  I  am delighted to be here at Gift City to ina...   \n",
       "3        NMS4  2017-02-01  I congratulate the Finance Minister Arun Jaitl...   \n",
       "4        NMS5  2017-02-05  Sri Pejavar Math’s most respected Sri Vishwesh...   \n",
       "...       ...         ...                                                ...   \n",
       "1177  NMS1178  2023-04-09  My colleagues in the Union Cabinet Shri Bhupen...   \n",
       "1178  NMS1179  2023-04-12  Namaskar! \\n\\nThe campaign to provide governme...   \n",
       "1179  NMS1180  2023-04-12  Namaskar, Governor of Rajasthan Shri Kalraj Mi...   \n",
       "1180  NMS1181  2023-04-14  Governor of Assam Shri Gulab Chand Kataria ji,...   \n",
       "1181  NMS1182  2023-04-15  President of the World Bank, Her Excellency, t...   \n",
       "\n",
       "                                                  Title  \\\n",
       "0     PM's Address at the Inauguration of the 104th ...   \n",
       "1     Text of PM's address at the Inauguration of No...   \n",
       "2     Text of PM’s address on the occasion of Inaugu...   \n",
       "3     English rendering of the Prime Minister’s Stat...   \n",
       "4     English rendering of the text of PM’s address ...   \n",
       "...                                                 ...   \n",
       "1177  English rendering of PM’s address at the inaug...   \n",
       "1178  English rendering of PM’s address at training ...   \n",
       "1179  English rendering of PM’s address during flagg...   \n",
       "1180  English rendering of PM’s address at inaugurat...   \n",
       "1181  Text of Prime Minister’s video message at the ...   \n",
       "\n",
       "                                         Cleaned_Speech  \\\n",
       "0     ['governor andhra pradesh shri e l narasimhan ...   \n",
       "1     ['chief minister gujarat shri vijay rupani ji ...   \n",
       "2     ['delighted gift city inaugurate india first i...   \n",
       "3     ['congratulate finance minister arun jaitley j...   \n",
       "4     ['sri pejavar math respected sri vishwesh tirt...   \n",
       "...                                                 ...   \n",
       "1177  ['colleague union cabinet shri bhupender yadav...   \n",
       "1178  ['namaskar', 'campaign provide government job ...   \n",
       "1179  ['namaskar governor rajasthan shri kalraj mish...   \n",
       "1180  ['governor assam shri gulab chand kataria ji c...   \n",
       "1181  ['president world bank excellency minister ene...   \n",
       "\n",
       "                                  Cleaned_Speech_string  \n",
       "0     governor andhra pradesh shri e l narasimhan ch...  \n",
       "1     chief minister gujarat shri vijay rupani ji co...  \n",
       "2     delighted gift city inaugurate india first int...  \n",
       "3     congratulate finance minister arun jaitley jee...  \n",
       "4     sri pejavar math respected sri vishwesh tirth ...  \n",
       "...                                                 ...  \n",
       "1177  colleague union cabinet shri bhupender yadav j...  \n",
       "1178  namaskar campaign provide government job youth...  \n",
       "1179  namaskar governor rajasthan shri kalraj mishra...  \n",
       "1180  governor assam shri gulab chand kataria ji chi...  \n",
       "1181  president world bank excellency minister energ...  \n",
       "\n",
       "[1182 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final code \n",
    "def vectorize(corpus):\n",
    "\n",
    "    corpus_tokenized = [nltk.word_tokenize(sentence) for sentence in corpus]\n",
    "    \n",
    "    model = Word2Vec(sentences=corpus_tokenized, vector_size=300, window=5, min_count=5, workers=4)\n",
    "\n",
    "    vectors = []\n",
    "\n",
    "    for sentence in corpus_tokenized:\n",
    "        sent_vec = []\n",
    "        for word in sentence:\n",
    "            if word in model.wv.key_to_index:\n",
    "                # If the word is in the Word2Vec model's vocabulary, extract its vector\n",
    "                word_vector = model.wv.get_vector(word)\n",
    "                sent_vec.append(word_vector)\n",
    "        vectors.append(sent_vec)\n",
    "\n",
    "    return vectors \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "you must first build vocabulary before training the model",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Vectorize the cleaned text data in the 'Cleaned_Speech' column\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m# using the 'vectorize' function and create a new column 'Vectorized_Speech'\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m# to store the vectorized data\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m df_data[\u001b[39m'\u001b[39m\u001b[39mvectorize\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df_data[\u001b[39m'\u001b[39;49m\u001b[39mCleaned_Speech\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mapply(vectorize)\n",
      "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\series.py:4771\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4661\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[0;32m   4662\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   4663\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4666\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   4667\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[0;32m   4668\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   4669\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4670\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4769\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4770\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4771\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py:1123\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1120\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[0;32m   1122\u001b[0m \u001b[39m# self.f is Callable\u001b[39;00m\n\u001b[1;32m-> 1123\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py:1174\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1172\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1173\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[1;32m-> 1174\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[0;32m   1175\u001b[0m             values,\n\u001b[0;32m   1176\u001b[0m             f,\n\u001b[0;32m   1177\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[0;32m   1178\u001b[0m         )\n\u001b[0;32m   1180\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1181\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1182\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1183\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_libs\\lib.pyx:2924\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[6], line 6\u001b[0m, in \u001b[0;36mvectorize\u001b[1;34m(corpus)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvectorize\u001b[39m(corpus):\n\u001b[0;32m      4\u001b[0m     corpus_tokenized \u001b[39m=\u001b[39m [nltk\u001b[39m.\u001b[39mword_tokenize(sentence) \u001b[39mfor\u001b[39;00m sentence \u001b[39min\u001b[39;00m corpus]\n\u001b[1;32m----> 6\u001b[0m     model \u001b[39m=\u001b[39m Word2Vec(sentences\u001b[39m=\u001b[39;49mcorpus_tokenized, vector_size\u001b[39m=\u001b[39;49m\u001b[39m300\u001b[39;49m, window\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m, min_count\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m, workers\u001b[39m=\u001b[39;49m\u001b[39m4\u001b[39;49m)\n\u001b[0;32m      8\u001b[0m     vectors \u001b[39m=\u001b[39m []\n\u001b[0;32m     10\u001b[0m     \u001b[39mfor\u001b[39;00m sentence \u001b[39min\u001b[39;00m corpus_tokenized:\n",
      "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gensim\\models\\word2vec.py:430\u001b[0m, in \u001b[0;36mWord2Vec.__init__\u001b[1;34m(self, sentences, corpus_file, vector_size, alpha, window, min_count, max_vocab_size, sample, seed, workers, min_alpha, sg, hs, negative, ns_exponent, cbow_mean, hashfxn, epochs, null_word, trim_rule, sorted_vocab, batch_words, compute_loss, callbacks, comment, max_final_vocab, shrink_windows)\u001b[0m\n\u001b[0;32m    428\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_corpus_sanity(corpus_iterable\u001b[39m=\u001b[39mcorpus_iterable, corpus_file\u001b[39m=\u001b[39mcorpus_file, passes\u001b[39m=\u001b[39m(epochs \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m))\n\u001b[0;32m    429\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuild_vocab(corpus_iterable\u001b[39m=\u001b[39mcorpus_iterable, corpus_file\u001b[39m=\u001b[39mcorpus_file, trim_rule\u001b[39m=\u001b[39mtrim_rule)\n\u001b[1;32m--> 430\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain(\n\u001b[0;32m    431\u001b[0m         corpus_iterable\u001b[39m=\u001b[39;49mcorpus_iterable, corpus_file\u001b[39m=\u001b[39;49mcorpus_file, total_examples\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcorpus_count,\n\u001b[0;32m    432\u001b[0m         total_words\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcorpus_total_words, epochs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepochs, start_alpha\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49malpha,\n\u001b[0;32m    433\u001b[0m         end_alpha\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmin_alpha, compute_loss\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_loss, callbacks\u001b[39m=\u001b[39;49mcallbacks)\n\u001b[0;32m    434\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    435\u001b[0m     \u001b[39mif\u001b[39;00m trim_rule \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gensim\\models\\word2vec.py:1045\u001b[0m, in \u001b[0;36mWord2Vec.train\u001b[1;34m(self, corpus_iterable, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m   1042\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_alpha \u001b[39m=\u001b[39m end_alpha \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_alpha\n\u001b[0;32m   1043\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepochs \u001b[39m=\u001b[39m epochs\n\u001b[1;32m-> 1045\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_training_sanity(epochs\u001b[39m=\u001b[39;49mepochs, total_examples\u001b[39m=\u001b[39;49mtotal_examples, total_words\u001b[39m=\u001b[39;49mtotal_words)\n\u001b[0;32m   1046\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_corpus_sanity(corpus_iterable\u001b[39m=\u001b[39mcorpus_iterable, corpus_file\u001b[39m=\u001b[39mcorpus_file, passes\u001b[39m=\u001b[39mepochs)\n\u001b[0;32m   1048\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_lifecycle_event(\n\u001b[0;32m   1049\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1050\u001b[0m     msg\u001b[39m=\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1054\u001b[0m     ),\n\u001b[0;32m   1055\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gensim\\models\\word2vec.py:1554\u001b[0m, in \u001b[0;36mWord2Vec._check_training_sanity\u001b[1;34m(self, epochs, total_examples, total_words, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     logger\u001b[39m.\u001b[39mwarning(\u001b[39m\"\u001b[39m\u001b[39mEffective \u001b[39m\u001b[39m'\u001b[39m\u001b[39malpha\u001b[39m\u001b[39m'\u001b[39m\u001b[39m higher than previous training cycles\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1553\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwv\u001b[39m.\u001b[39mkey_to_index:  \u001b[39m# should be set by `build_vocab`\u001b[39;00m\n\u001b[1;32m-> 1554\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39myou must first build vocabulary before training the model\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1555\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwv\u001b[39m.\u001b[39mvectors):\n\u001b[0;32m   1556\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39myou must initialize vectors before training the model\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: you must first build vocabulary before training the model"
     ]
    }
   ],
   "source": [
    "# Vectorize the cleaned text data in the 'Cleaned_Speech' column\n",
    "# using the 'vectorize' function and create a new column 'Vectorized_Speech'\n",
    "# to store the vectorized data\n",
    "df_data['vectorize'] = df_data['Cleaned_Speech'].apply(vectorize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
