{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "\n",
    "# Set up OpenAI API credentials\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "# Define a function to perform NER using OpenAI API\n",
    "def perform_ner(input_speech):\n",
    "    try:\n",
    "        # Call the OpenAI API for NER\n",
    "        response = openai.Completion.create(\n",
    "            engine=\"text-davinci-002\",\n",
    "            prompt=f\"Perform NER on the following speech: \\n\\n{input_speech}\\n\\n recognize named entities and categorize them into Name, Location including but not restricted to Indian States and Union Territories, orgnization, date, misc\",\n",
    "            max_tokens=1024,\n",
    "            n=1,\n",
    "            stop=None\n",
    "        )\n",
    "\n",
    "        # Extract the recognized named entities from the API response\n",
    "        named_entities = response.choices[0].text.strip()\n",
    "\n",
    "        return named_entities\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "# Create a new column \"NER\" to store the recognized named entities\n",
    "df_NER[\"NER\"] = \"\"\n",
    "\n",
    "# Create a new column \"Error\" to store the error flag\n",
    "df_NER[\"Error\"] = 0\n",
    "\n",
    "# Loop over each row in the dataframe\n",
    "for index, row in df_NER.iterrows():\n",
    "    input_speech = row[\"Cleaned_Speech_string\"]\n",
    "    named_entities = perform_ner(input_speech)\n",
    "    if named_entities == \"\":\n",
    "        df_NER.at[index, \"Error\"] = 1\n",
    "    # Store the recognized named entities in the \"NER\" column\n",
    "    df_NER.at[index, \"NER\"] = named_entities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import openai\n",
    "import pandas as pd\n",
    "\n",
    "# Set up OpenAI API credentials\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "# Define a function to perform NER using OpenAI API\n",
    "def perform_ner(input_speech):\n",
    "    try:\n",
    "        # Call the OpenAI API for NER\n",
    "        response = openai.Completion.create(\n",
    "            engine=\"text-davinci-002\",\n",
    "            prompt=f\"Perform NER on the following speech: \\n\\n{input_speech}\\n\\n recognize named entities and categorize them into Name, Location including but not restricted to Indian States and Union Territories, orgnization, date, misc\",\n",
    "            max_tokens=1024,\n",
    "            n=1,\n",
    "            stop=None\n",
    "        )\n",
    "\n",
    "        # Extract the recognized named entities from the API response\n",
    "        named_entities = response.choices[0].text.strip()\n",
    "\n",
    "        return named_entities, 0\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return \"\", 1\n",
    "\n",
    "\n",
    "# Create a new column \"NER\" to store the recognized named entities\n",
    "df_NER[\"NER\"] = \"\"\n",
    "\n",
    "# Create a new column \"Error_Flag\" to indicate if an error occurred during NER\n",
    "df_NER[\"Error_Flag\"] = 0\n",
    "\n",
    "# Loop over each row in the dataframe\n",
    "for index, row in df_NER.iterrows():\n",
    "    input_speech = row[\"Cleaned_Speech_string\"]\n",
    "    # Split long speeches into multiple parts\n",
    "    parts = [input_speech[i:i+4096] for i in range(0, len(input_speech), 4096)]\n",
    "    named_entities = \"\"\n",
    "    error_flag = 0\n",
    "    # Perform NER on each part separately\n",
    "    for part in parts:\n",
    "        part_entities, part_error_flag = perform_ner(part)\n",
    "        named_entities += part_entities\n",
    "        error_flag += part_error_flag\n",
    "    # Store the recognized named entities and error flag in their respective columns\n",
    "    df_NER.at[index, \"NER\"] = named_entities\n",
    "    df_NER.at[index, \"Error_Flag\"] = error_flag\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "\n",
    "# Set up OpenAI API credentials\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "# Define a function to perform NER using OpenAI API\n",
    "def perform_ner(input_speech):\n",
    "    try:\n",
    "        # Call the OpenAI API for NER\n",
    "        response = openai.Completion.create(\n",
    "            engine=\"text-davinci-002\",\n",
    "            prompt=f\"Perform NER on the following speech: \\n\\n{input_speech}\\n\\n recognize named entities and categorize them into Name, Location including but not restricted to Indian States and Union Territories, orgnization, date, misc\",\n",
    "            max_tokens=1024,\n",
    "            n=1,\n",
    "            stop=None\n",
    "        )\n",
    "\n",
    "        # Extract the recognized named entities from the API response\n",
    "        named_entities = response.choices[0].text.strip()\n",
    "\n",
    "        return named_entities\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# Load the dataframe with \"Cleaned_Speech\" column\n",
    "df_NER = pd.read_csv(\"speeches.csv\")\n",
    "\n",
    "# Create a new column \"NER\" to store the recognized named entities\n",
    "df_NER[\"NER\"] = \"\"\n",
    "\n",
    "# Loop over each row in the dataframe\n",
    "for index, row in df_NER.iterrows():\n",
    "    input_speech = row[\"Cleaned_Speech_string\"]\n",
    "    # Split long speeches into multiple parts\n",
    "    parts = [input_speech[i:i+4096] for i in range(0, len(input_speech), 4096)]\n",
    "    named_entities = \"\"\n",
    "    # Perform NER on each part separately\n",
    "    for part in parts:\n",
    "        part_entities = perform_ner(part)\n",
    "        named_entities += part_entities\n",
    "    # Store the recognized named entities in the \"NER\" column\n",
    "    df_NER.at[index, \"NER\"] = named_entities\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
